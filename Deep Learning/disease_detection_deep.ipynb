{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea1WORZsMoac",
        "outputId": "55585bc8-cdeb-4a4f-c500-45f8ba6087c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DwGFXVlhNiL6"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/archive.zip\" -d \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v2rldkx1V3gk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import math\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qqv87Q_-V3gn",
        "outputId": "63cae32e-f5cb-4d74-ffba-d9fffecd32d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 24\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 25\n",
        "GAMMA = 0.1\n",
        "\n",
        "# CPU or GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U-Vc6h07V3gp"
      },
      "outputs": [],
      "source": [
        "dictionary = {\n",
        "    0: 'Apple___Apple_scab',\n",
        "    1: 'Apple___Black_rot',\n",
        "    2: 'Apple___Cedar_apple_rust',\n",
        "    3: 'Apple___healthy',\n",
        "    4: 'Blueberry___healthy',\n",
        "    5: 'Cherry_(including_sour)___healthy',\n",
        "    6: 'Cherry_(including_sour)___Powdery_mildew',\n",
        "    7: 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
        "    8: 'Corn_(maize)___Common_rust_',\n",
        "    9: 'Corn_(maize)___healthy',\n",
        "    10: 'Corn_(maize)___Northern_Leaf_Blight',\n",
        "    11: 'Grape___Black_rot',\n",
        "    12: 'Grape___Esca_(Black_Measles)',\n",
        "    13: 'Grape___healthy',\n",
        "    14: 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
        "    15: 'Orange___Haunglongbing_(Citrus_greening)',\n",
        "    16: 'Peach___Bacterial_spot',\n",
        "    17: 'Peach___healthy',\n",
        "    18: 'Pepper,_bell___Bacterial_spot',\n",
        "    19: 'Pepper,_bell___healthy',\n",
        "    20: 'Potato___Early_blight',\n",
        "    21: 'Potato___healthy',\n",
        "    22: 'Potato___Late_blight',\n",
        "    23: 'Raspberry___healthy',\n",
        "    24: 'Soybean___healthy',\n",
        "    25: 'Squash___Powdery_mildew',\n",
        "    26: 'Strawberry___healthy',\n",
        "    27: 'Strawberry___Leaf_scorch',\n",
        "    28: 'Tomato___Bacterial_spot',\n",
        "    29: 'Tomato___Early_blight',\n",
        "    30: 'Tomato___healthy',\n",
        "    31: 'Tomato___Late_blight',\n",
        "    32: 'Tomato___Leaf_Mold',\n",
        "    33: 'Tomato___Septoria_leaf_spot',\n",
        "    34: 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
        "    35: 'Tomato___Target_Spot',\n",
        "    36: 'Tomato___Tomato_mosaic_virus',\n",
        "    37: 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__jVCeKuV3gr"
      },
      "outputs": [],
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "def label_folder(folder_path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    i = 0\n",
        "    for img_path in os.listdir(folder_path):\n",
        "        if i < 400 :\n",
        "            i = i + 1\n",
        "            if img_path.endswith('.jpg') or img_path.endswith('.png') or img_path.endswith('.jpeg') or img_path.endswith('.JPG'):\n",
        "                img = io.imread(str(folder_path)+'/'+str(img_path))\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "            else: \n",
        "                print(img_path)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    x_train.extend(images)\n",
        "    y_train.extend(labels)\n",
        "    \n",
        "## load data\n",
        "for i in range (38):\n",
        "    folder_path = os.path.join('/content/data/plantvillage dataset/color/', dictionary[i])\n",
        "    label_folder(folder_path , i)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVUzrwvPV3gt"
      },
      "outputs": [],
      "source": [
        "image_size = (224, 224, 3)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        images, targets = sample\n",
        "        images = resize(images, image_size).reshape(3, 224, 224)\n",
        "        return torch.from_numpy(np.asarray(images)), torch.from_numpy(np.asarray(targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwExS1DeV3gv"
      },
      "outputs": [],
      "source": [
        "# transformers, read dataset and split, loader\n",
        "\n",
        "class DiseaseDataset(Dataset):\n",
        "\n",
        "    def __init__(self,imgaes, labels, transform= None):\n",
        "        self.n_samples = len(labels)\n",
        "        self.x_data = imgaes # size [n_samples, n_features]\n",
        "        self.y_data = labels # size [n_samples, 1]\n",
        "        self.transform = transform\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.transform((self.x_data[index], self.y_data[index]))\n",
        "        return sample\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALbMSHDhV3gw"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
        "test_transform = transforms.Compose([ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(x_train, y_train, test_size=0.2)\n",
        "\n",
        "train_dataset = DiseaseDataset(train_images, train_labels, transform = ToTensor())\n",
        "test_dataset = DiseaseDataset(test_images, test_labels, transform = ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBBf2Wu-V3gx"
      },
      "outputs": [],
      "source": [
        "# calculate accuraccy\n",
        "def calc_accuracy(data_loader, model, device):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in data_loader:\n",
        "            data = data.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "\n",
        "            outputs = model(data.float())\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return len(data_loader.dataset), correct, total\n",
        "\n",
        "    # print( \"Accuracy of the %d test images is %d %%\"\n",
        "    #     % (len(data_loader.dataset), 100 * correct / total) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YuwYBLfV3gy"
      },
      "outputs": [],
      "source": [
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\",],\n",
        "    \"VGG19\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\",],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_net(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=1000):\n",
        "        super(VGG_net, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(x),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = x\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfYTdGMpYsJ4",
        "outputId": "a828ceaf-543c-4b7b-b137-374a18a304e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG_net(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU()\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU()\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU()\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU()\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU()\n",
              "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU()\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU()\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU()\n",
              "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fcs): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=38, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = VGG_net(in_channels=3, num_classes=38).float()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/vgg16.pth'\n",
        "\n",
        "path=torch.load(PATH)\n",
        "model.load_state_dict(path)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Srhi3UAPV3gz",
        "outputId": "ea37d71a-e638-435d-e6c1-afe9ed9127e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/25], Step [491/491], Loss: 0.8687\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "def train():\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "        # training the model\n",
        "        # model.train()\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU\n",
        "            data = data.to(DEVICE)\n",
        "            target = target.to(DEVICE)\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data.float())\n",
        "            # calculate the batch loss\n",
        "            # target = torch.max(target, 1)[1]\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss wrt model parameters\n",
        "            loss.backward()\n",
        "            # perform a ingle optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            \n",
        "        # validate the model\n",
        "        model.eval()\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "\n",
        "        print (f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5bJVidXaqoZ",
        "outputId": "32e6571d-8e9a-43d6-c7e3-bb9772ec2c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the 1890 test images is 85 %\n"
          ]
        }
      ],
      "source": [
        "length, correct, total = calc_accuracy(test_loader, model, DEVICE)\n",
        "\n",
        "print( \"Accuracy of the %d test images is %d %%\" % (length, 100 * correct / total) )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "disease_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
